{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дисклеймер \n",
    "Целью данной работы было исключительно изучение использования пайплайна и использования самописных классов для преобразования данных в пайплайне. Так же в работе были построены эмпириеские доверительные интервалы для сравнения результатов различных моделей.\n",
    "<br>\n",
    "В данной работе я не приследовал цель достичь максимально точных прогнозов, поэтому не проводил серьзного EDA, не расматривал precession, recall и f-metric, не балансировал датасет и др."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Первичное изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Смотрим типы данных по колонкам, размер датасета и количество пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Разделяем колонки по типам данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = df.select_dtypes(include=['int64','float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Surname', 'Geography', 'Gender'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Geography', 'Gender'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = cat[1:]\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance',\n",
       "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
       "       'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = num[2:-1]\n",
    "num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Категориальные переменнные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography    3\n",
       "Gender       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Количественные переменные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Смотрим базовые статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore           Age        Tenure        Balance  NumOfProducts  \\\n",
       "count  10000.000000  10000.000000  10000.000000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800      5.012800   76485.889288       1.530200   \n",
       "std       96.653299     10.487806      2.892174   62397.405202       0.581654   \n",
       "min      350.000000     18.000000      0.000000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000      3.000000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000      5.000000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000      7.000000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000     10.000000  250898.090000       4.000000   \n",
       "\n",
       "         HasCrCard  IsActiveMember  EstimatedSalary        Exited  \n",
       "count  10000.00000    10000.000000     10000.000000  10000.000000  \n",
       "mean       0.70550        0.515100    100090.239881      0.203700  \n",
       "std        0.45584        0.499797     57510.492818      0.402769  \n",
       "min        0.00000        0.000000        11.580000      0.000000  \n",
       "25%        0.00000        0.000000     51002.110000      0.000000  \n",
       "50%        1.00000        1.000000    100193.915000      0.000000  \n",
       "75%        1.00000        1.000000    149388.247500      0.000000  \n",
       "max        1.00000        1.000000    199992.480000      1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2:].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные кажутся довольно простыми, из явных осложняющих факторов - разбалансировка датасета (более 75% имеют целевую переменную 0),  построим первичную модель по данным as-is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "стоит так же отметить:<br>\n",
    "не менее 25% имеют нулевой баланс, возможно это только кредитные клиенты, возможно это отток или что то еще <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом данные кажутся пригодными для построения модели AS-IS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Построение базовой модели на данных AS-IS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создадим классы для удобства построения пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Трансформер для выбора нечисловых колонок\n",
    "    \"\"\"\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Трансформер для выбора числовых колонок\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Трансформер для ONE HOT ENCODING\"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in self.columns:\n",
    "            if col_ not in test_columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание пайплайна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создадим список  трансформеров, преобразующих данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transformers = list()\n",
    "#Категориальные переменные выбираются и подвергаются OHE\n",
    "for cat_col in cat:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', FeatureSelector(column=cat_col)),\n",
    "                ('ohe', OHEncoder(key=cat_col))\n",
    "            ])\n",
    "    final_transformers.append((cat_col, cat_transformer))\n",
    "#Количественные переменные выбираются и подвергаются масштабированию\n",
    "for cont_col in num:\n",
    "    cont_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                 ('scaler', StandardScaler())\n",
    "            ])\n",
    "    final_transformers.append((cont_col, cont_transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Geography',\n",
       "  Pipeline(steps=[('selector', FeatureSelector(column='Geography')),\n",
       "                  ('ohe', OHEncoder(key='Geography'))])),\n",
       " ('Gender',\n",
       "  Pipeline(steps=[('selector', FeatureSelector(column='Gender')),\n",
       "                  ('ohe', OHEncoder(key='Gender'))])),\n",
       " ('CreditScore',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='CreditScore')),\n",
       "                  ('scaler', StandardScaler())])),\n",
       " ('Age',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='Age')),\n",
       "                  ('scaler', StandardScaler())])),\n",
       " ('Tenure',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='Tenure')),\n",
       "                  ('scaler', StandardScaler())])),\n",
       " ('Balance',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='Balance')),\n",
       "                  ('scaler', StandardScaler())])),\n",
       " ('NumOfProducts',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='NumOfProducts')),\n",
       "                  ('scaler', StandardScaler())])),\n",
       " ('HasCrCard',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='HasCrCard')),\n",
       "                  ('scaler', StandardScaler())])),\n",
       " ('IsActiveMember',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='IsActiveMember')),\n",
       "                  ('scaler', StandardScaler())])),\n",
       " ('EstimatedSalary',\n",
       "  Pipeline(steps=[('selector', NumberSelector(key='EstimatedSalary')),\n",
       "                  ('scaler', StandardScaler())]))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Объединим список трансформеров в один трансформер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion(final_transformers)\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Добавим классификатор (любой, позже классификатор будет меняться как настраиваемый параметр)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создадим сетку параметров логистической регрессии для gridsearch cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'classifier':[LogisticRegression()],\n",
    "     'classifier__penalty':[ 'l2'],\n",
    "     'classifier__solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "     },\n",
    "    \n",
    "    {'classifier':[LogisticRegression()],\n",
    "     'classifier__penalty':['l1'],\n",
    "     'classifier__solver':[ 'liblinear', 'saga']\n",
    "     },\n",
    "    \n",
    "    {'classifier':[LogisticRegression()],\n",
    "     'classifier__penalty':['none'],\n",
    "     'classifier__solver':[ 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "     },\n",
    "    \n",
    "    {'classifier':[LogisticRegression()],\n",
    "     'classifier__penalty':['elasticnet'],\n",
    "     'classifier__solver':['saga'],\n",
    "     'classifier__l1_ratio':[0.01,0.05,0.1,0.3,0.5,0.7, 0.9]\n",
    "     }\n",
    "    \n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подберем лучшие параметры для пайплайна с классификатором-логистической регрессией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=16, \n",
    "                           scoring='roc_auc',\n",
    "                          #refit = 'roc_auc', \n",
    "                           n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=16,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('Geography',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         FeatureSelector(column='Geography')),\n",
       "                                                                                        ('ohe',\n",
       "                                                                                         OHEncoder(key='Geography'))])),\n",
       "                                                                       ('Gender',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         FeatureSelector(column='Gender')),\n",
       "                                                                                        ('ohe',\n",
       "                                                                                         OHEncoder(key='Gender'))])),\n",
       "                                                                       ('CreditScore',\n",
       "                                                                        Pipeline(steps=[('select...\n",
       "                          'classifier__penalty': ['l1'],\n",
       "                          'classifier__solver': ['liblinear', 'saga']},\n",
       "                         {'classifier': [LogisticRegression()],\n",
       "                          'classifier__penalty': ['none'],\n",
       "                          'classifier__solver': ['newton-cg', 'lbfgs', 'sag',\n",
       "                                                 'saga']},\n",
       "                         {'classifier': [LogisticRegression()],\n",
       "                          'classifier__l1_ratio': [0.01, 0.05, 0.1, 0.3, 0.5,\n",
       "                                                   0.7, 0.9],\n",
       "                          'classifier__penalty': ['elasticnet'],\n",
       "                          'classifier__solver': ['saga']}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(df,df['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = tuple(zip(grid_search.cv_results_['params'],grid_search.cv_results_['mean_test_score'],grid_search.cv_results_['std_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "({'classifier': LogisticRegression(solver='liblinear'), 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}, 0.7658373940335778, 0.016766120160210965)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}, 0.7658344811471126, 0.01673985266156785)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__l1_ratio': 0.3, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}, 0.7658315165327496, 0.016757347853326738)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__l1_ratio': 0.1, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}, 0.7658266099940765, 0.016750881669039357)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__l1_ratio': 0.5, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}, 0.7658217092029476, 0.01674865443502603)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__l1_ratio': 0.01, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}, 0.7658196983081071, 0.01675106229159882)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__l1_ratio': 0.05, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}, 0.7658196983081071, 0.01675005663259106)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__penalty': 'none', 'classifier__solver': 'lbfgs'}, 0.7658187733263055, 0.016755863375471827)\n",
      "\n",
      "({'classifier': LogisticRegression(solver='liblinear'), 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}, 0.7658177218985318, 0.016748485978697845)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__penalty': 'none', 'classifier__solver': 'saga'}, 0.7658168084118187, 0.016753848677916378)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__penalty': 'none', 'classifier__solver': 'newton-cg'}, 0.7658167969167302, 0.016756851627525427)\n",
      "\n",
      "({'classifier': LogisticRegression(solver='liblinear'), 'classifier__penalty': 'l2', 'classifier__solver': 'newton-cg'}, 0.7658147572841688, 0.01675103536498828)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__penalty': 'none', 'classifier__solver': 'sag'}, 0.7658128383500356, 0.016756223218150856)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__l1_ratio': 0.7, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}, 0.7658128038647702, 0.01674745488361981)\n",
      "\n",
      "({'classifier': LogisticRegression(solver='liblinear'), 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}, 0.7658127866221378, 0.016751499916544857)\n",
      "\n",
      "({'classifier': LogisticRegression(solver='liblinear'), 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}, 0.7658108217076508, 0.016747917172974764)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__l1_ratio': 0.9, 'classifier__penalty': 'elasticnet', 'classifier__solver': 'saga'}, 0.7657989517551106, 0.016766822710756867)\n",
      "\n",
      "({'classifier': LogisticRegression(), 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}, 0.7657969925881678, 0.016756144624665875)\n"
     ]
    }
   ],
   "source": [
    "for result in sorted(results, key = lambda x: x[1], reverse = True):\n",
    "    print('')\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(solver='liblinear'),\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__solver': 'liblinear'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7658373940335778"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создаем сетку параметров  для градиентного бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'classifier':[GradientBoostingClassifier()],\n",
    "     'classifier__n_estimators':[ 50, 100, 200, 500],\n",
    "     'classifier__max_depth':[1,5,10,15]\n",
    "     \n",
    "     }  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=16, \n",
    "                           scoring='roc_auc',\n",
    "                          #refit = 'roc_auc', \n",
    "                           n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=16,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('Geography',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         FeatureSelector(column='Geography')),\n",
       "                                                                                        ('ohe',\n",
       "                                                                                         OHEncoder(key='Geography'))])),\n",
       "                                                                       ('Gender',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         FeatureSelector(column='Gender')),\n",
       "                                                                                        ('ohe',\n",
       "                                                                                         OHEncoder(key='Gender'))])),\n",
       "                                                                       ('CreditScore',\n",
       "                                                                        Pipeline(steps=[('select...\n",
       "                                                                       ('EstimatedSalary',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         NumberSelector(key='EstimatedSalary')),\n",
       "                                                                                        ('scaler',\n",
       "                                                                                         StandardScaler())]))])),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'classifier': [GradientBoostingClassifier(max_depth=5,\n",
       "                                                                    n_estimators=50)],\n",
       "                          'classifier__max_depth': [1, 5, 10, 15],\n",
       "                          'classifier__n_estimators': [50, 100, 200, 500]}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(df,df['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = tuple(zip(grid_search.cv_results_['params'],grid_search.cv_results_['mean_test_score'],grid_search.cv_results_['std_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 5, 'classifier__n_estimators': 50}, 0.8654132811226717, 0.013321220898949566)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 5, 'classifier__n_estimators': 100}, 0.8651299556675625, 0.015500388915099873)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 5, 'classifier__n_estimators': 200}, 0.8590636001060556, 0.015564460452342615)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 1, 'classifier__n_estimators': 500}, 0.8519743802945408, 0.013712156179586607)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 1, 'classifier__n_estimators': 200}, 0.8507951163107541, 0.013463046415989203)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 5, 'classifier__n_estimators': 500}, 0.8475386130557139, 0.014686050923492747)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 1, 'classifier__n_estimators': 100}, 0.8455718831681239, 0.013066663981482641)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 15, 'classifier__n_estimators': 500}, 0.8426308645711528, 0.01721790392058879)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 10, 'classifier__n_estimators': 50}, 0.8422882678772231, 0.018320209898469716)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 10, 'classifier__n_estimators': 100}, 0.8407621270654813, 0.018133414580132835)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 10, 'classifier__n_estimators': 200}, 0.8406652277577311, 0.016139194521894728)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 10, 'classifier__n_estimators': 500}, 0.8387447826415932, 0.015405853733855661)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 15, 'classifier__n_estimators': 200}, 0.8379068880646439, 0.017074338341499063)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 1, 'classifier__n_estimators': 50}, 0.8337377964997615, 0.012602233523864498)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 15, 'classifier__n_estimators': 100}, 0.8283424043697922, 0.019389762110808305)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50), 'classifier__max_depth': 15, 'classifier__n_estimators': 50}, 0.8061805304834215, 0.02348101351768485)\n"
     ]
    }
   ],
   "source": [
    "for result in sorted(results, key = lambda x: x[1], reverse = True):\n",
    "    print('')\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50),\n",
       " 'classifier__max_depth': 5,\n",
       " 'classifier__n_estimators': 50}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8654132811226717"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Лучшие параметры, лучший скор, стандартное отклонение скора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50),\n",
       "  'classifier__max_depth': 5,\n",
       "  'classifier__n_estimators': 50},\n",
       " 0.8654031749205715,\n",
       " 0.01323004871746928)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key = lambda x: x[1], reverse = True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "базовые модели показывают довольно неплохие результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Проверка лучшей базовой модели, фиксация ее метрик качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline.set_params(**\n",
    "                          {'classifier': GradientBoostingClassifier(max_depth=5, n_estimators=50, random_state = 0),\n",
    "                           'classifier__max_depth': 5,\n",
    "                           'classifier__n_estimators': 50}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df['Exited'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('Geography',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Geography')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEncoder(key='Geography'))])),\n",
       "                                                ('Gender',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Gender')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEncoder(key='Gender'))])),\n",
       "                                                ('CreditScore',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='Credi...\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('IsActiveMember',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='IsActiveMember')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('EstimatedSalary',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='EstimatedSalary')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())]))])),\n",
       "                ('classifier',\n",
       "                 GradientBoostingClassifier(max_depth=5, n_estimators=50,\n",
       "                                            random_state=0))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8747502267078079"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, clf.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проверка подтвердила результаты кросс валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Более точный подбор параметров модели (Построение улучшенной модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'classifier':[GradientBoostingClassifier()],\n",
    "     'classifier__n_estimators':[ 30, 50, 60],\n",
    "     'classifier__max_depth':[3,4,5]\n",
    "     \n",
    "     }  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'classifier':[GradientBoostingClassifier()],\n",
    "     'classifier__n_estimators':[50, 1000, 2000],\n",
    "     'classifier__max_depth':[3,4,5,6,7],\n",
    "     'classifier__learning_rate':[0.1,0.05,0.01]\n",
    "     \n",
    "     }  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=16, \n",
    "                           scoring='roc_auc',\n",
    "                          #refit = 'roc_auc', \n",
    "                           n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=16,\n",
       "             estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('Geography',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         FeatureSelector(column='Geography')),\n",
       "                                                                                        ('ohe',\n",
       "                                                                                         OHEncoder(key='Geography'))])),\n",
       "                                                                       ('Gender',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         FeatureSelector(column='Gender')),\n",
       "                                                                                        ('ohe',\n",
       "                                                                                         OHEncoder(key='Gender'))])),\n",
       "                                                                       ('Tenure',\n",
       "                                                                        Pipeline(steps=[('selector',\n",
       "                                                                                         F...\n",
       "                                                                                         StandardScaler())]))])),\n",
       "                                       ('classifier',\n",
       "                                        GradientBoostingClassifier(max_depth=5,\n",
       "                                                                   n_estimators=50,\n",
       "                                                                   random_state=0))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'classifier': [GradientBoostingClassifier(learning_rate=0.01,\n",
       "                                                                    n_estimators=2000)],\n",
       "                          'classifier__learning_rate': [0.1, 0.05, 0.01],\n",
       "                          'classifier__max_depth': [3, 4, 5, 6, 7],\n",
       "                          'classifier__n_estimators': [50, 1000, 2000]}],\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(df,df['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = tuple(zip(grid_search.cv_results_['params'],grid_search.cv_results_['mean_test_score'],grid_search.cv_results_['std_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000),\n",
       " 'classifier__learning_rate': 0.01,\n",
       " 'classifier__max_depth': 3,\n",
       " 'classifier__n_estimators': 2000}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8672860311598178"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 3, 'classifier__n_estimators': 2000}, 0.8672860311598178, 0.014294696346008022)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 3, 'classifier__n_estimators': 1000}, 0.8666572182911936, 0.013942771077807678)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 4, 'classifier__n_estimators': 1000}, 0.8664458083769869, 0.014064296182898495)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__n_estimators': 50}, 0.8663459740158918, 0.013539394567718138)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 4, 'classifier__n_estimators': 2000}, 0.8654579017160031, 0.014347271406213133)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__n_estimators': 50}, 0.8654363128837058, 0.013699739863893601)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 1000}, 0.8650027876173414, 0.013618344914990798)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 3, 'classifier__n_estimators': 1000}, 0.8646366989083589, 0.01481811295008999)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 50}, 0.8642656189387952, 0.013325380465625742)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 6, 'classifier__n_estimators': 50}, 0.8631381183321876, 0.013296507979477396)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 5, 'classifier__n_estimators': 50}, 0.8629690459624874, 0.013885962836139363)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 6, 'classifier__n_estimators': 50}, 0.8624093710796654, 0.01454204201494812)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 2000}, 0.860833277600174, 0.013367530529303952)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 7, 'classifier__n_estimators': 50}, 0.8607440114815965, 0.01474416193556408)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 6, 'classifier__n_estimators': 1000}, 0.8606246525575361, 0.014548285708477892)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 7, 'classifier__n_estimators': 50}, 0.8600139890975601, 0.013921230910324692)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 4, 'classifier__n_estimators': 50}, 0.8589998738059255, 0.013029007067577926)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 3, 'classifier__n_estimators': 2000}, 0.8589203287729194, 0.014281966103937794)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 1000}, 0.8586714812043688, 0.013455701723937475)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 4, 'classifier__n_estimators': 1000}, 0.8581573365957851, 0.014209585331825855)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 7, 'classifier__n_estimators': 1000}, 0.857714454544948, 0.015268905763398063)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 6, 'classifier__n_estimators': 2000}, 0.855192550552123, 0.013970754667986453)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 7, 'classifier__n_estimators': 50}, 0.8544891083231008, 0.014619048078974088)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 6, 'classifier__n_estimators': 50}, 0.8544107381036616, 0.01534009414786486)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 3, 'classifier__n_estimators': 50}, 0.8528449978153317, 0.013112174084128809)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 7, 'classifier__n_estimators': 2000}, 0.8510262107871294, 0.013276737608280529)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 5, 'classifier__n_estimators': 1000}, 0.8499246889404726, 0.01226398485165899)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 50}, 0.8492437716478238, 0.013015151012979589)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 4, 'classifier__n_estimators': 2000}, 0.8491777183068547, 0.012583863297181305)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 2000}, 0.8487009115472868, 0.012738198293049615)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__n_estimators': 1000}, 0.8477663603332236, 0.014476943755828088)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 6, 'classifier__n_estimators': 1000}, 0.8444672338341289, 0.013569944991534874)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 7, 'classifier__n_estimators': 1000}, 0.8413675545126966, 0.013991555409746783)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 5, 'classifier__n_estimators': 2000}, 0.8409593853297723, 0.01289360507912599)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__n_estimators': 1000}, 0.8406598691824742, 0.01133644016080451)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 4, 'classifier__n_estimators': 2000}, 0.8386315579161117, 0.012496703939850336)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 6, 'classifier__n_estimators': 2000}, 0.8370047084485994, 0.013274085463820397)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 6, 'classifier__n_estimators': 1000}, 0.8369333385515816, 0.013280610541781292)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.05, 'classifier__max_depth': 7, 'classifier__n_estimators': 2000}, 0.8367941511126713, 0.015794401277130617)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 4, 'classifier__n_estimators': 50}, 0.835480431332431, 0.014195911325029438)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 7, 'classifier__n_estimators': 1000}, 0.8347589975036833, 0.014540524550396656)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__n_estimators': 2000}, 0.8321585099177246, 0.012075545476615962)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 6, 'classifier__n_estimators': 2000}, 0.8318533619227441, 0.013751505333866525)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.1, 'classifier__max_depth': 7, 'classifier__n_estimators': 2000}, 0.8318410759101398, 0.016862988963800753)\n",
      "\n",
      "({'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000), 'classifier__learning_rate': 0.01, 'classifier__max_depth': 3, 'classifier__n_estimators': 50}, 0.8197156528906386, 0.014160308648210516)\n"
     ]
    }
   ],
   "source": [
    "for result in sorted(results, key = lambda x: x[1], reverse = True):\n",
    "    print('')\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline.set_params(**\n",
    "                          {'classifier': GradientBoostingClassifier(learning_rate=0.01, n_estimators=2000),\n",
    "                           'classifier__learning_rate': 0.01,\n",
    "                           'classifier__max_depth': 3,\n",
    "                           'classifier__n_estimators': 2000}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df['Exited'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('Geography',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Geography')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEncoder(key='Geography'))])),\n",
       "                                                ('Gender',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Gender')),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OHEncoder(key='Gender'))])),\n",
       "                                                ('Tenure',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  FeatureSelector(column='Tenure...\n",
       "                                                                  NumberSelector(key='HasCrCard')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('IsActiveMember',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='IsActiveMember')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('EstimatedSalary',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='EstimatedSalary')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())]))])),\n",
       "                ('classifier',\n",
       "                 GradientBoostingClassifier(learning_rate=0.01,\n",
       "                                            n_estimators=2000))])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8751982151508902"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, clf.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получиось добиться некоторого улучшения качества, однако, оно скорее всего незначимо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8751982151508902"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, clf.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение эмпирического доверитльного интервала"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Генерирум разные ROC_AUC для данной модели на бутсрапах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный ROC_AUC: 0.875\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.stats import sem\n",
    "\n",
    "\n",
    "\n",
    "y_pred = clf.decision_function(X_test)\n",
    "y_true = np.array(y_test)\n",
    "\n",
    "\n",
    "print(\"Исходный ROC_AUC: {:0.3f}\".format(roc_auc_score(y_true, y_pred)))\n",
    "\n",
    "\n",
    "n_bootstraps = 1000\n",
    "rnd_seed = 0  \n",
    "bootstrapped_scores = []\n",
    "\n",
    "\n",
    "rnd = np.random.RandomState(rnd_seed)\n",
    "for i in range(n_bootstraps):\n",
    "    # bootstrap by sampling with replacement on the prediction indices\n",
    "    indices = rnd.random_integers(0, len(y_pred) - 1, len(y_pred))\n",
    "    if len(np.unique(y_true[indices])) < 2:\n",
    "        # We need at least one positive and one negative sample for ROC AUC\n",
    "        # to be defined: reject the sample\n",
    "        continue\n",
    "\n",
    "\n",
    "    score = roc_auc_score(y_true[indices], y_pred[indices])\n",
    "    bootstrapped_scores.append(score)\n",
    "    #print(\"Bootstrap #{} ROC area: {:0.3f}\".format(i + 1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8460889263980811, 0.9015676270391936, 1000)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(bootstrapped_scores), np.max(bootstrapped_scores), len(bootstrapped_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Строим 95% доверительный интервал по бутстрапированным roc auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85713737, 0.89129335])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_int = np.percentile(bootstrapped_scores, (2.5, 97.5))\n",
    "conf_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#средняя оценка качества лучшей из базовых моделей на градиентном бустинге\n",
    "basic_bosting_roc_auc = 0.8654031749205715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(conf_int)< basic_bosting_roc_auc and basic_bosting_roc_auc<max(conf_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "улучшенная бустинговая модель хоть не имеет статистически значимого улучшения относительно базовой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cредняя оценка качества лучшей из базовых логистических регрессий\n",
    "basic_logreg_roc_auc = 0.7658373940335778 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(conf_int)<= basic_logreg_roc_auc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "улучшенная бустинговая модель значимо (на 95% доверительном интервале) лучше чем базовая модель на логистической регрессии"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
